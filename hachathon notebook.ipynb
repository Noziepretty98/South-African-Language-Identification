{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Assessment\n",
    "This assessment is for determining how much you have learnt in the past few sprints, the results of which will be used to determine how EDSA can best prepare you for the working world. This assessment consists of theory and practical questions in Regression, Classification, and NLP.\n",
    "\n",
    "The answers for this test will be input into Athena as Multiple Choice Questions. The questions are included in this notebook and are made ** bold ** and numbered according to the Athena Questions.\n",
    "\n",
    "As this is a time-constrained assessment, if you are struggling with a question, rather move on to a task you are better prepared to answer rather than spending unnecessary time on one question.\n",
    "\n",
    "**_Good Luck!_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Machine Learning Theory Questions\n",
    "Lets start with a couple theoretical questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q1. Which of the following would be considered a sign of overfitting? **\n",
    "\n",
    "A) Much lower testing error than training error.\n",
    "\n",
    "B) Equal training and testing error.\n",
    "\n",
    "C) Very large testing error.\n",
    "\n",
    "D) Much lower training error than testing error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q2. In the equation below, what does ```a``` represent? **\n",
    "\n",
    "$$\n",
    "y = ax + b\n",
    "$$\n",
    "\n",
    "A) a is the y-intercept of the linear model.\n",
    "\n",
    "B) a is the x-intercept of the linear model.\n",
    "\n",
    "C) a is the slope, or gradient, of the linear model.\n",
    "\n",
    "D) a is an unknown quantity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q3. What is true about the function below? **\n",
    "\n",
    "$$\n",
    "y = 3x + 2\n",
    "$$\n",
    "\n",
    "A) The y-variable is always 2 units greater than the x-variable.\n",
    "\n",
    "B) If we increase the x-variable by 2 units, the y-variable will increase by 1 unit.\n",
    "\n",
    "C) When the value of the x-variable is 2, the y-variable will be equal to 0.\n",
    "\n",
    "D) When the value of the x-variable is 0, the y-variable will be equal to 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q4. Into what interval does the logistic function transform the response? **\n",
    "\n",
    "A. Between -1 and 1\n",
    "\n",
    "B. Between 0 and 1\n",
    "\n",
    "C. Between Minus infinity and 0\n",
    "\n",
    "D. Between 0 and infinity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Machine Learning Practical Questions\n",
    "**_Note_** While there are other ways to obtain the answers for the Athena questions, we recommend writing the following functions to ensure you get the correct answers.\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import string\n",
    "from nltk import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the data\n",
    "For this assessment we will be using a dataset about the quality of wine. This dataset will be used for both the classification and regression questions. Read in the data and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('winequality.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Data pre-processing\n",
    "\n",
    "Write a function to pre-process the data so that we can run it through the classifier. The function should:\n",
    "* Split the data into features and labels\n",
    "* Standardise the features using sklearn's ```StandardScaler```\n",
    "* Split the data into 70% training and 30% testing data\n",
    "* Set random_state to equal 42 for this internal method\n",
    "* If there are any NAN values, fill them with zeros\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take a dataframe as input.\n",
    "* Should return two `tuples` of the form `(X_train, y_train), (X_test, y_test)`.\n",
    "\n",
    "**Note: be sure to pay attention to the test size and random state you use as the following questions assume you split the data correctly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_preprocess(df):\n",
    "    \n",
    "    #your code here\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = data_preprocess(df)\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "print(X_test[7])\n",
    "print(y_test[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "\n",
    "```python\n",
    "(X_train, y_train), (X_test, y_test) = data_preprocess(df)\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "print(X_test[7])\n",
    "print(y_test[7])\n",
    "\n",
    "[-0.57136659 -0.83357715 -1.02610916 -0.26533465 -0.61846572 -0.79974133\n",
    " -0.48035289 -0.31396599 -1.32623327 -0.26925241 -1.0773326   0.50996897]\n",
    "7\n",
    "[ 1.75018984 -0.07953061  1.88358789 -0.95318049 -0.76558683  0.39882967\n",
    " -0.98745132 -1.34019672  0.76818761  1.12849668  0.46278438 -1.16701119]\n",
    "5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q5. What is the result of printing out X_train[10][5]? ** \n",
    "\n",
    "** Q6. What is the result of printing out X_test[10][5]? ** \n",
    "\n",
    "** Q7. What is the result of printing out y_train[10]? ** \n",
    "\n",
    "** Q8. What is the result of printing out y_test[10]? ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Training a Logistic Regression Model\n",
    "\n",
    "Now that we have formatted our data, we can fit a model using sklearn's `LogisticRegression` class with its default parameters. Write a function that will take as input `(X_train, y_train)` that we created previously, and return a trained model.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two numpy `arrays` as input in the form `(X_train, y_train)`.\n",
    "* Should return an sklearn `LogisticRegression` model.\n",
    "* The returned model should be fitted to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    \n",
    "    #your code here\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q9. What is the intercept term of the fitted model? ** \n",
    "\n",
    "** Q10. What is the value of lm.coef_[1][3]? ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Testing Classification model\n",
    "\n",
    "Now that you have trained your model, let's see how well it does on the test set. Write a function which returns the accuracy of your trained model when tested with the test set.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take the fitted model and two numpy `arrays` `X_test, y_test` as input.\n",
    "* Should return a `float` of the accuracy of the model. This number should be between zero and one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(lm, X_test, y_test):\n",
    "    \n",
    "    #your code here\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_accuracy(lm,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q11. What is the accuracy of this Logistic Regression model? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - Train Random Forest Classifier model\n",
    "\n",
    "Let us try improve this accuracy by training a model using sklearn's `RandomForestClassifier` class with its random_state is set to 6. We'll write a function that will take as input the features and label variables that we created previously, and return a trained model.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two numpy `arrays` as input in the form `(X_train, y_train)`.\n",
    "* Should return an sklearn `RandomForestClassifier` model which has a random state of 6.\n",
    "* The returned model should be fitted to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def train_rf_model\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have trained your model, lets see how well it does on the test set. Use the calculate_accuracy function you previously created to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_accuracy(clf,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q12. What is the accuracy of this Random Forest model? ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 - Train Linear Regression Model\n",
    "\n",
    "Since this dataset is about predicting quality, which ranges from 1 to 10, lets try fit the data to a regression model instead of a classification model and see how well that performs.\n",
    "\n",
    "Fit a model using sklearn's `LinearRegression` class with its default parameters. Write a function that will take as input `(X_train, y_train)` that we created previously, and return a trained model.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two numpy `arrays` as input in the form `(X_train, y_train)`.\n",
    "* Should return an sklearn `LinearRegression` model.\n",
    "* The returned model should be fitted to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_reg_model(X_train, y_train):\n",
    "    \n",
    "    #your code here\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q13. What is the result of printing out reg.intercept_? ** \n",
    "\n",
    "** Q14. What is the result of printing out reg.coef_[1]? ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 - Test Regression Model\n",
    "\n",
    "We would now like to test our regression model. This test should give the residual sum of squares, which for your convenience is written as\n",
    "$$\n",
    "RSS = \\sum_{i=1}^N (p_i - y_i)^2,\n",
    "$$\n",
    "where $p_i$ refers to the $i^{\\rm th}$ prediction made from `X_test`, $y_i$ refers to the $i^{\\rm th}$ value in `y_test`, and $N$ is the length of `y_test`.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take a trained model and two `arrays` as input. This will be the `X_test` and `y_test` variables. \n",
    "* Should return the residual sum of squares over the input from the predicted values of `X_test` as compared to values of `y_test`.\n",
    "* The output should be a `float` rounded to 2 decimal places.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q15. What is the RSS value for this Linear Regression Model? ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7 - Train Decision Tree Regresson Model\n",
    "\n",
    "Let us try improve this accuracy by training a model using sklearn's `DecisionTreeRegressor` class with a random state value of 10. Write a function that will take as input `(X_train, y_train)` that we created previously, and return a trained model.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two numpy `arrays` as input in the form `(X_train, y_train)`.\n",
    "* Should return an sklearn `DecisionTreeRegressor` model with a random state value of 10.\n",
    "* The returned model should be fitted to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have trained your model, lets see how well it does on the test set. Use the function you previously created to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q16. What is the RSS value for this Decision Tree Regression Model? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8 - Compare Classification and Regression\n",
    "\n",
    "How do these regression models compare to the classification models? Its hard to compare residual sum of squares and accuracy. Lets do something simple to compare them. Lets round the regression predictions to their closest integer, and use those values to calculate accuracy.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take the fitted model and two numpy `arrays` `X_test, y_test` as input.\n",
    "* Caluclate the model predictions and round them to their closest integer.\n",
    "* Should return a `float` of the accuracy of the model. This number should be between zero and one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_reg_class(model, X_test, y_test):\n",
    "    \n",
    "    #your code here\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compare_reg_class(reg,  X_test, y_test))\n",
    "print(compare_reg_class(dt,  X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q17. What is the accuracy of your Linear Regression Model? ** \n",
    "\n",
    "** Q18. What is the accuracy of your Decision Tree Regression Model? ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9 - Mean Absolute Error\n",
    "Write a function to compute the Mean Absolute Error (MAE), which is given by:\n",
    "\n",
    "$$\n",
    "MAE = \\frac{1}{N} \\sum_{n=i}^N |p_i - y_i|\n",
    "$$\n",
    "\n",
    "where $p_i$ refers to the $i^{\\rm th}$ `prediction`, $y_i$ refers to the $i^{\\rm th}$ value in `y_test`, and $N$ is the length of `y_test`.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two `arrays` as input. You can think of these the `predictions` and `y_test` variables you get when testing a model. \n",
    "* Should return the mean absolute error over the input from the predicted values of `X_test` as compared to values of `y_test`.\n",
    "* The output should be a `float` rounded to 2 decimal places.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def mean_abs_err\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_abs_err(np.array([5,7,1.2]),np.array([3.2,2,2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q19. What is the result of printing out mean_abs_err(np.array([1,1,1]),np.array([2,2,2]))? ** \n",
    "\n",
    "** Q20. What is the result of printing out mean_abs_err(np.array([5,7,1.2]),np.array([3.2,2,2]))? ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 - Natural Language Processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Q21. Which of the following would be considered a stop word? **\n",
    "\n",
    "A) and\n",
    "\n",
    "B) book\n",
    "\n",
    "C) like\n",
    "\n",
    "D) always"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the data\n",
    "For the practical questions lets read in the first chapter of Treasure Island written by Robert Louis Stevenson. The text file treasure_island.txt contains only this first chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('treasure_island.txt', 'r', encoding='ISO-8859-1').read()\n",
    "print(data[:863])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10 - Text pre-processing\n",
    "Write a function that removes the punctuation from the text and converts all the letters to lowercase letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 11 - Tokenisation\n",
    "Tokenise the data using nltk's TreebankWorkTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q22. What is the 133rd token in this chapter? **\n",
    "\n",
    "** Q23. What is the 21st token in this chapter? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 12 - Count\n",
    "Write a function which counts the number of times a word occurs in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q24. How many times does the word \"admiral\" appear in the text? **\n",
    "\n",
    "** Q25. How many times does the word \"captain\" appear in the text? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
